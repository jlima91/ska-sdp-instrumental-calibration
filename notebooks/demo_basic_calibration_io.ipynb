{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter notebook to demonstrate the basic calibration setup\n",
    "\n",
    "This notebook runs the following tasks:\n",
    "* Create a test Visibility dataset.\n",
    "   * Not adding visibility sample noise. Just testing that things are working exactly as expected.\n",
    "   * Using the GLEAM sky model and a common everybeam station beam model.\n",
    "   * Add complex Gaussian noise corruptions to X and Y station gains.\n",
    "* Save the dataset as a MS so that it can be read back in.\n",
    "* Read it back in sub-bands.\n",
    "* Some pre-processing.\n",
    "* Predict model visibilities (using GLEAM and everybeam).\n",
    "* Do bandpass calibration.\n",
    "* Use dask to handle processing of different frequency sub-bands.\n",
    "\n",
    "This notebook requires:\n",
    "* See imports.\n",
    "\n",
    "#### Note: need to comment out a few xarray files to run!\n",
    "* xarray/core/parallel.py: line 194\n",
    "* xarray/core/indexes.py: conditional starting at line 1400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen abc>:106: FutureWarning: xarray subclass Visibility should explicitly define __slots__\n"
     ]
    }
   ],
   "source": [
    "# Demonstration of basic calibration\n",
    "\n",
    "# pylint cannot seem to handle astropy units\n",
    "# pylint: disable=no-member\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# Imports\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "from astropy import units\n",
    "from astropy.coordinates import Angle, SkyCoord\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from ska_sdp_datamodels.calibration.calibration_create import (\n",
    "    create_gaintable_from_visibility,\n",
    ")\n",
    "from ska_sdp_datamodels.calibration.calibration_functions import (\n",
    "    export_gaintable_to_hdf5,\n",
    ")\n",
    "from ska_sdp_datamodels.configuration.config_create import (\n",
    "    create_named_configuration,\n",
    ")\n",
    "from ska_sdp_datamodels.science_data_model import PolarisationFrame\n",
    "from ska_sdp_datamodels.visibility.vis_create import create_visibility\n",
    "from ska_sdp_datamodels.visibility.vis_io_ms import export_visibility_to_ms\n",
    "\n",
    "from ska_sdp_instrumental_calibration.data_managers.dask_wrappers import (\n",
    "    load_ms,\n",
    "    predict_vis,\n",
    "    run_solver,\n",
    ")\n",
    "from ska_sdp_instrumental_calibration.processing_tasks.calibration import (\n",
    "    apply_gaintable,\n",
    ")\n",
    "from ska_sdp_instrumental_calibration.processing_tasks.lsm_tmp import (\n",
    "    convert_model_to_skycomponents,\n",
    "    generate_lsm,\n",
    ")\n",
    "from ska_sdp_instrumental_calibration.processing_tasks.predict import (\n",
    "    predict_from_components,\n",
    ")\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "log = logging.getLogger()\n",
    "log.setLevel(logging.INFO)\n",
    "log.addHandler(logging.StreamHandler(sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline config\n",
    "\n",
    "gleamfile = \"/data/EOS_1/mit183/gleamegc.dat\"\n",
    "eb_ms = \"/data/EOS_1/mit183/SKA/SP-4626/OSKAR_MOCK.ms\"\n",
    "eb_coeffs = \"/data/EOS_1/mit183/SKA/SP-4626/ska-sdp-func-everybeam/coeffs\"\n",
    "\n",
    "ms_name = \"demo.ms\"\n",
    "hdf5_name = \"demo.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a local dask cluster and client\n",
    "\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using AA2-Low-ECP-240228 with 68 stations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 14:14:07,348 - processing_tasks.lsm_tmp - INFO - extracted 37 GLEAM components\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted 37 GLEAM components\n",
      "Initialising beams for Low\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n"
     ]
    }
   ],
   "source": [
    "# Create a test Visibility dataset\n",
    "\n",
    "# -------------------------------------------------------------------------- #\n",
    "# Set up the array\n",
    "\n",
    "# Read in an array configuration\n",
    "low_config = create_named_configuration(\"LOWBD2\")\n",
    "\n",
    "# Down-select to a desired sub-array\n",
    "#  - ECP-240228 modified AA2 clusters:\n",
    "#      Southern Arm: S8 (x6), S9, S10 (x6), S13, S15, S16\n",
    "#      Northern Arm: N8, N9, N10, N13, N15, N16\n",
    "#      Eastern Arm: E8, E9, E10, E13.\n",
    "#  - Most include only 4 of 6 stations, so just use the first 4:\n",
    "AA2 = (\n",
    "    np.concatenate(\n",
    "        (\n",
    "            345 + np.arange(6),  # S8-1:6\n",
    "            351 + np.arange(4),  # S9-1:4\n",
    "            429 + np.arange(6),  # S10-1:6\n",
    "            447 + np.arange(4),  # S13-1:4\n",
    "            459 + np.arange(4),  # S15-1:4\n",
    "            465 + np.arange(4),  # S16-1:4\n",
    "            375 + np.arange(4),  # N8-1:4\n",
    "            381 + np.arange(4),  # N9-1:4\n",
    "            471 + np.arange(4),  # N10-1:4\n",
    "            489 + np.arange(4),  # N13-1:4\n",
    "            501 + np.arange(4),  # N15-1:4\n",
    "            507 + np.arange(4),  # N16-1:4\n",
    "            315 + np.arange(4),  # E8-1:4\n",
    "            321 + np.arange(4),  # E9-1:4\n",
    "            387 + np.arange(4),  # E10-1:4\n",
    "            405 + np.arange(4),  # E13-1:4\n",
    "        )\n",
    "    )\n",
    "    - 1\n",
    ")\n",
    "mask = np.isin(low_config.id.data, AA2)\n",
    "nstations = low_config.stations.shape[0]\n",
    "low_config = low_config.sel(indexers={\"id\": np.arange(nstations)[mask]})\n",
    "\n",
    "# Reset relevant station parameters\n",
    "nstations = low_config.stations.shape[0]\n",
    "low_config.stations.data = np.arange(nstations).astype(\"str\")\n",
    "low_config = low_config.assign_coords(id=np.arange(nstations))\n",
    "# low_config.attrs[\"name\"] = low_config.name+\"-AA2\"\n",
    "low_config.attrs[\"name\"] = \"AA2-Low-ECP-240228\"\n",
    "\n",
    "print(f\"Using {low_config.name} with {nstations} stations\")\n",
    "\n",
    "# -------------------------------------------------------------------------- #\n",
    "# Set up the observation\n",
    "\n",
    "# Set the phase centre in the ICRS coordinate frame\n",
    "ra0 = Angle(0.0 * units.hourangle)\n",
    "dec0 = Angle(-27.0 * units.deg)\n",
    "\n",
    "# Set the parameters of sky model components\n",
    "# chanwidth = 400e6 / 512  # station/CBF coarse channels = 781.25 kHz\n",
    "chanwidth = 5.4e3  # Hz\n",
    "nfrequency = 64\n",
    "frequency = 781.25e3 * 160 + chanwidth * np.arange(nfrequency)\n",
    "sample_time = 0.9  # seconds\n",
    "solution_interval = sample_time  # would normally be minutes\n",
    "\n",
    "# Set the phase centre hour angle range for the sim (in radians)\n",
    "ha0 = 1 * np.pi / 12  # radians\n",
    "ha = ha0 + np.arange(0, solution_interval, sample_time) / 3600 * np.pi / 12\n",
    "\n",
    "# Create the Visibility dataset\n",
    "vis = create_visibility(\n",
    "    low_config,\n",
    "    ha,\n",
    "    frequency,\n",
    "    channel_bandwidth=[chanwidth] * len(frequency),\n",
    "    polarisation_frame=PolarisationFrame(\"linear\"),\n",
    "    phasecentre=SkyCoord(ra=ra0, dec=dec0),\n",
    "    weight=1.0,\n",
    ")\n",
    "\n",
    "# Generate a true sky model and true visibilties for the whole band\n",
    "fov = 10.0\n",
    "flux_limit = 1\n",
    "tsm = generate_lsm(\n",
    "    gleamfile=gleamfile,\n",
    "    phasecentre=vis.phasecentre,\n",
    "    fov=fov,\n",
    "    flux_limit=flux_limit,\n",
    ")\n",
    "\n",
    "tsm_components = convert_model_to_skycomponents(tsm, vis.frequency.data)\n",
    "predict_from_components(vis, tsm_components, eb_coeffs=eb_coeffs, eb_ms=eb_ms)\n",
    "\n",
    "# Apply random complex antenna gains\n",
    "#  - Ignore polarisation for now. Just get basic calibration working.\n",
    "jones = create_gaintable_from_visibility(\n",
    "    vis, jones_type=\"B\", timeslice=solution_interval\n",
    ")\n",
    "g_sigma = 0.1\n",
    "jones.gain.data[..., 0, 0] = (\n",
    "    np.random.normal(1, g_sigma, jones.gain.shape[:3])\n",
    "    + np.random.normal(0, g_sigma, jones.gain.shape[:3]) * 1j\n",
    ")\n",
    "jones.gain.data[..., 1, 1] = (\n",
    "    np.random.normal(1, g_sigma, jones.gain.shape[:3])\n",
    "    + np.random.normal(0, g_sigma, jones.gain.shape[:3]) * 1j\n",
    ")\n",
    "\n",
    "vis = apply_gaintable(vis=vis, gt=jones, inverse=False)\n",
    "\n",
    "# Export vis to a file\n",
    "export_visibility_to_ms(ms_name, [vis])\n",
    "\n",
    "vis = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading uni. fields [0], uni. data descs [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 14:14:14,394 - processing_tasks.lsm_tmp - INFO - extracted 37 GLEAM components\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted 37 GLEAM components\n"
     ]
    }
   ],
   "source": [
    "# Do pre-processing\n",
    "\n",
    "# Set the number of channels in each frequency chunk\n",
    "fchunk = 16\n",
    "\n",
    "# Read in the Visibility dataset in chunks\n",
    "vis = load_ms(ms_name, fchunk)\n",
    "\n",
    "# This triggers an extra load, but but is worth checking\n",
    "# assert np.all(vis.vis.data == create_visibility_from_ms(ms_name)[0].vis.data)\n",
    "\n",
    "# Get the LSM (single call for all channels / dask tasks)\n",
    "lsm = generate_lsm(\n",
    "    gleamfile=gleamfile,\n",
    "    phasecentre=vis.phasecentre,\n",
    "    fov=fov,\n",
    "    flux_limit=flux_limit,\n",
    ")\n",
    "\n",
    "# Adapative RFI flagging\n",
    "#  - Is triggering the computation as is, so leave it for now.\n",
    "#  - Move to dask_wrappers? RFI flagging may need bandwidth...\n",
    "# vis = rfi_flagger(vis)\n",
    "\n",
    "# Averaging of Visibility datasets in time or frequency.\n",
    "#  - Presumably use dask parallelism.\n",
    "#  - Done as part of chunking?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict model visibilities\n",
    "modelvis = predict_vis(vis, lsm, eb_ms=eb_ms, eb_coeffs=eb_coeffs)\n",
    "\n",
    "# Make sure modelvis was updated\n",
    "# This triggers an extra load, but but is worth checking\n",
    "# assert np.all(modelvis.vis.data[..., [0, 3]] != 0), \"vis should have changed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen abc>:106: FutureWarning: xarray subclass Visibility should explicitly define __slots__\n",
      "<frozen abc>:106: FutureWarning: xarray subclass Visibility should explicitly define __slots__\n",
      "<frozen abc>:106: FutureWarning: xarray subclass Visibility should explicitly define __slots__\n",
      "<frozen abc>:106: FutureWarning: xarray subclass Visibility should explicitly define __slots__\n",
      "/u/mit183/.pyenv/versions/3.11.7/lib/python3.11/site-packages/ska_sdp_datamodels/visibility/vis_model.py:190: FutureWarning: the `pandas.MultiIndex` object(s) passed as 'baselines' coordinate(s) or data variable(s) will no longer be implicitly promoted and wrapped into multiple indexed coordinates in the future (i.e., one coordinate for each multi-index level + one dimension coordinate). If you want to keep this behavior, you need to first wrap it explicitly using `mindex_coords = xarray.Coordinates.from_pandas_multiindex(mindex_obj, 'dim')` and pass it as coordinates, e.g., `xarray.Dataset(coords=mindex_coords)`, `dataset.assign_coords(mindex_coords)` or `dataarray.assign_coords(mindex_coords)`.\n",
      "  return cls(datavars, coords=coords, attrs=attrs)\n",
      "/u/mit183/.pyenv/versions/3.11.7/lib/python3.11/site-packages/ska_sdp_datamodels/visibility/vis_model.py:190: FutureWarning: the `pandas.MultiIndex` object(s) passed as 'baselines' coordinate(s) or data variable(s) will no longer be implicitly promoted and wrapped into multiple indexed coordinates in the future (i.e., one coordinate for each multi-index level + one dimension coordinate). If you want to keep this behavior, you need to first wrap it explicitly using `mindex_coords = xarray.Coordinates.from_pandas_multiindex(mindex_obj, 'dim')` and pass it as coordinates, e.g., `xarray.Dataset(coords=mindex_coords)`, `dataset.assign_coords(mindex_coords)` or `dataarray.assign_coords(mindex_coords)`.\n",
      "  return cls(datavars, coords=coords, attrs=attrs)\n",
      "/u/mit183/.pyenv/versions/3.11.7/lib/python3.11/site-packages/ska_sdp_datamodels/visibility/vis_model.py:190: FutureWarning: the `pandas.MultiIndex` object(s) passed as 'baselines' coordinate(s) or data variable(s) will no longer be implicitly promoted and wrapped into multiple indexed coordinates in the future (i.e., one coordinate for each multi-index level + one dimension coordinate). If you want to keep this behavior, you need to first wrap it explicitly using `mindex_coords = xarray.Coordinates.from_pandas_multiindex(mindex_obj, 'dim')` and pass it as coordinates, e.g., `xarray.Dataset(coords=mindex_coords)`, `dataset.assign_coords(mindex_coords)` or `dataarray.assign_coords(mindex_coords)`.\n",
      "  return cls(datavars, coords=coords, attrs=attrs)\n",
      "/u/mit183/.pyenv/versions/3.11.7/lib/python3.11/site-packages/ska_sdp_datamodels/visibility/vis_model.py:190: FutureWarning: the `pandas.MultiIndex` object(s) passed as 'baselines' coordinate(s) or data variable(s) will no longer be implicitly promoted and wrapped into multiple indexed coordinates in the future (i.e., one coordinate for each multi-index level + one dimension coordinate). If you want to keep this behavior, you need to first wrap it explicitly using `mindex_coords = xarray.Coordinates.from_pandas_multiindex(mindex_obj, 'dim')` and pass it as coordinates, e.g., `xarray.Dataset(coords=mindex_coords)`, `dataset.assign_coords(mindex_coords)` or `dataarray.assign_coords(mindex_coords)`.\n",
      "  return cls(datavars, coords=coords, attrs=attrs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# Do the bandpass calibration\n",
    "\n",
    "refant = 0\n",
    "\n",
    "gaintable = run_solver(vis=vis, modelvis=modelvis, refant=refant).load()\n",
    "\n",
    "# Do some phase referencing for comparisons\n",
    "inputdata = jones.gain.data * np.exp(\n",
    "    -1j * np.angle(jones.gain.data[:, [refant], :, :, :])\n",
    ")\n",
    "\n",
    "assert np.all(\n",
    "    np.isclose(gaintable.gain.data, inputdata)\n",
    "), \"Calibration should have converged.\"\n",
    "\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shut down the scheduler and workers\n",
    "client.close()\n",
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output hdf5 file\n",
    "export_gaintable_to_hdf5([gaintable], hdf5_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
