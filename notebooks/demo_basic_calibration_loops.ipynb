{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter notebook to demonstrate the basic calibration setup\n",
    "\n",
    "This notebook runs the following tasks:\n",
    "* Create a test Visibility dataset.\n",
    "   * Not adding visibility sample noise. Just testing that things are working exactly as expected.\n",
    "   * Using the GLEAM sky model and a common everybeam station beam model.\n",
    "   * Add complex Gaussian noise corruptions to X and Y station gains.\n",
    "* Some pre-processing.\n",
    "* Predict model visibilities (using GLEAM and everybeam).\n",
    "* Do bandpass calibration.\n",
    "\n",
    "This notebook requires:\n",
    "* See imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen abc>:106: FutureWarning: xarray subclass Visibility should explicitly define __slots__\n"
     ]
    }
   ],
   "source": [
    "# Demonstration of basic calibration\n",
    "\n",
    "# pylint cannot seem to handle astropy units\n",
    "# pylint: disable=no-member\n",
    "\n",
    "import importlib\n",
    "\n",
    "# Imports\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import xarray\n",
    "from astropy import units\n",
    "from astropy.coordinates import Angle, SkyCoord\n",
    "\n",
    "# from ska_sdp_func_python.calibration.operations import apply_gaintable\n",
    "from ska_sdp_datamodels.calibration.calibration_create import (\n",
    "    create_gaintable_from_visibility,\n",
    ")\n",
    "from ska_sdp_datamodels.configuration.config_create import (\n",
    "    create_named_configuration,\n",
    ")\n",
    "from ska_sdp_datamodels.science_data_model import PolarisationFrame\n",
    "from ska_sdp_datamodels.visibility.vis_create import create_visibility\n",
    "from ska_sdp_func_python.preprocessing.flagger import rfi_flagger\n",
    "\n",
    "from ska_sdp_instrumental_calibration.processing_tasks.beams import (\n",
    "    GenericBeams,\n",
    ")\n",
    "from ska_sdp_instrumental_calibration.processing_tasks.calibration import (\n",
    "    apply_gaintable,\n",
    "    solve_bandpass,\n",
    ")\n",
    "from ska_sdp_instrumental_calibration.processing_tasks.lsm_tmp import (\n",
    "    convert_model_to_skycomponents,\n",
    "    generate_lsm,\n",
    ")\n",
    "from ska_sdp_instrumental_calibration.processing_tasks.predict import (\n",
    "    predict_from_components,\n",
    ")\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions (might move some to package)\n",
    "\n",
    "\n",
    "def get_slice_lims(length, nslice):\n",
    "    \"\"\"Generate a list of slice index limits for n slices.\n",
    "\n",
    "    Generate indices to slice a list into a number of equal-length slices.\n",
    "    Allow the final slice to be smaller if need be.\n",
    "\n",
    "    :param length: length of list to be sliced.\n",
    "    \"\"\"\n",
    "    slice_lim0 = np.arange(0, length, int(np.ceil(length / nslice)))\n",
    "    return np.stack((slice_lim0, np.append(slice_lim0[1:], length))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using AA2-Low-ECP-240228 with 68 stations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 16:43:18,342 - ska_sdp_instrumental_calibration.processing_tasks.lsm_tmp - INFO - extracted 37 GLEAM components\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: EVERYBEAM_DATADIR=/data/EOS_1/mit183/SKA/SP-4626/ska-sdp-func-everybeam/coeffs\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n",
      "Could not load dataset for frequency 125 MHz, using the nearest neighbor with frequency 137 MHz instead\n"
     ]
    }
   ],
   "source": [
    "# Create a test Visibility dataset\n",
    "\n",
    "# -------------------------------------------------------------------------- #\n",
    "# Set up the array\n",
    "\n",
    "# Read in an array configuration\n",
    "low_config = create_named_configuration(\"LOWBD2\")\n",
    "\n",
    "# Down-select to a desired sub-array\n",
    "#  - ECP-240228 modified AA2 clusters:\n",
    "#      Southern Arm: S8 (x6), S9, S10 (x6), S13, S15, S16\n",
    "#      Northern Arm: N8, N9, N10, N13, N15, N16\n",
    "#      Eastern Arm: E8, E9, E10, E13.\n",
    "#  - Most include only 4 of 6 stations, so just use the first 4:\n",
    "AA2 = (\n",
    "    np.concatenate(\n",
    "        (\n",
    "            345 + np.arange(6),  # S8-1:6\n",
    "            351 + np.arange(4),  # S9-1:4\n",
    "            429 + np.arange(6),  # S10-1:6\n",
    "            447 + np.arange(4),  # S13-1:4\n",
    "            459 + np.arange(4),  # S15-1:4\n",
    "            465 + np.arange(4),  # S16-1:4\n",
    "            375 + np.arange(4),  # N8-1:4\n",
    "            381 + np.arange(4),  # N9-1:4\n",
    "            471 + np.arange(4),  # N10-1:4\n",
    "            489 + np.arange(4),  # N13-1:4\n",
    "            501 + np.arange(4),  # N15-1:4\n",
    "            507 + np.arange(4),  # N16-1:4\n",
    "            315 + np.arange(4),  # E8-1:4\n",
    "            321 + np.arange(4),  # E9-1:4\n",
    "            387 + np.arange(4),  # E10-1:4\n",
    "            405 + np.arange(4),  # E13-1:4\n",
    "        )\n",
    "    )\n",
    "    - 1\n",
    ")\n",
    "mask = np.isin(low_config.id.data, AA2)\n",
    "nstations = low_config.stations.shape[0]\n",
    "low_config = low_config.sel(indexers={\"id\": np.arange(nstations)[mask]})\n",
    "\n",
    "# Reset relevant station parameters\n",
    "nstations = low_config.stations.shape[0]\n",
    "low_config.stations.data = np.arange(nstations).astype(\"str\")\n",
    "low_config = low_config.assign_coords(id=np.arange(nstations))\n",
    "# low_config.attrs[\"name\"] = low_config.name+\"-AA2\"\n",
    "low_config.attrs[\"name\"] = \"AA2-Low-ECP-240228\"\n",
    "\n",
    "print(f\"Using {low_config.name} with {nstations} stations\")\n",
    "\n",
    "# -------------------------------------------------------------------------- #\n",
    "# Set up the observation\n",
    "\n",
    "# Set the phase centre in the ICRS coordinate frame\n",
    "ra0 = Angle(0.0 * units.hourangle)\n",
    "dec0 = Angle(-27.0 * units.deg)\n",
    "\n",
    "# Set the parameters of sky model components\n",
    "# chanwidth = 400e6 / 512  # station/CBF coarse channels = 781.25 kHz\n",
    "chanwidth = 5.4e3  # Hz\n",
    "nfrequency = 64\n",
    "frequency = 781.25e3 * 160 + chanwidth * np.arange(nfrequency)\n",
    "sample_time = 0.9  # seconds\n",
    "solution_interval = sample_time  # would normally be minutes\n",
    "\n",
    "# Set the phase centre hour angle range for the sim (in radians)\n",
    "ha0 = 1 * np.pi / 12  # radians\n",
    "ha = ha0 + np.arange(0, solution_interval, sample_time) / 3600 * np.pi / 12\n",
    "\n",
    "# Create the Visibility dataset\n",
    "vis = create_visibility(\n",
    "    low_config,\n",
    "    ha,\n",
    "    frequency,\n",
    "    channel_bandwidth=[chanwidth] * len(frequency),\n",
    "    polarisation_frame=PolarisationFrame(\"linear\"),\n",
    "    phasecentre=SkyCoord(ra=ra0, dec=dec0),\n",
    "    weight=1.0,\n",
    ")\n",
    "\n",
    "# Generate a true sky model and true visibilties for the whole band\n",
    "gleamfile = \"/data/EOS_1/mit183/gleamegc.dat\"\n",
    "fov = 10.0\n",
    "flux_limit = 1\n",
    "tsm = generate_lsm(\n",
    "    gleamfile=gleamfile,\n",
    "    phasecentre=vis.phasecentre,\n",
    "    fov=fov,\n",
    "    flux_limit=flux_limit,\n",
    ")\n",
    "ms_path = \"/data/EOS_1/mit183/SKA/SP-4626/OSKAR_MOCK.ms\"\n",
    "%env EVERYBEAM_DATADIR=/data/EOS_1/mit183/SKA/SP-4626/ska-sdp-func-everybeam/coeffs\n",
    "beams = GenericBeams(vis=vis, array=\"Low\", ms_path=ms_path)\n",
    "\n",
    "tsm_components = convert_model_to_skycomponents(tsm, vis.frequency.data)\n",
    "predict_from_components(vis, tsm_components, beams=beams)\n",
    "\n",
    "# Possible future development:\n",
    "#  - Add thermal noise.\n",
    "#  - Use the GSM package.\n",
    "#  - Image-based sky models with degridding?\n",
    "#  - Generate an ionospheric phase screen and add direction-dependent delays.\n",
    "#  - Use the phase screen to add differential ionospheric Faraday rotation.\n",
    "\n",
    "# Apply random complex antenna gains\n",
    "#  - Ignore polarisation for now. Just get basic calibration working.\n",
    "jones = create_gaintable_from_visibility(\n",
    "    vis, jones_type=\"B\", timeslice=solution_interval\n",
    ")\n",
    "g_sigma = 0.1\n",
    "jones.gain.data[..., 0, 0] = (\n",
    "    np.random.normal(1, g_sigma, jones.gain.shape[:3])\n",
    "    + np.random.normal(0, g_sigma, jones.gain.shape[:3]) * 1j\n",
    ")\n",
    "jones.gain.data[..., 1, 1] = (\n",
    "    np.random.normal(1, g_sigma, jones.gain.shape[:3])\n",
    "    + np.random.normal(0, g_sigma, jones.gain.shape[:3]) * 1j\n",
    ")\n",
    "\n",
    "vis = apply_gaintable(vis=vis, gt=jones, inverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 16:43:23,416 - ska_sdp_instrumental_calibration.processing_tasks.lsm_tmp - INFO - extracted 37 GLEAM components\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: EVERYBEAM_DATADIR=/data/EOS_1/mit183/SKA/SP-4626/ska-sdp-func-everybeam/coeffs\n",
      "Calling ska_sdp_func_python preprocessing flagger rfi_flagger\n"
     ]
    }
   ],
   "source": [
    "# Do pre-processing\n",
    "\n",
    "# Get the LSM (single call for all channels / dask tasks)\n",
    "lsm = generate_lsm(\n",
    "    gleamfile=gleamfile,\n",
    "    phasecentre=vis.phasecentre,\n",
    "    fov=fov,\n",
    "    flux_limit=flux_limit,\n",
    ")\n",
    "\n",
    "%env EVERYBEAM_DATADIR=/data/EOS_1/mit183/SKA/SP-4626/ska-sdp-func-everybeam/coeffs\n",
    "beams = GenericBeams(vis=vis, array=\"Low\", ms_path=ms_path)\n",
    "\n",
    "# Adapative RFI flagging (assume known flags/birdies have been applied)\n",
    "#  - Could also use dask parallelism.\n",
    "#  - Should have already been done in the batch pre-processing pipeline\n",
    "# This works but requires ska_sdp_func:\n",
    "if importlib.util.find_spec(\"ska_sdp_func\") is not None:\n",
    "    print(\"Calling ska_sdp_func_python preprocessing flagger rfi_flagger\")\n",
    "    vis = rfi_flagger(vis)\n",
    "else:\n",
    "    print(\"ska_sdp_func is not available for rfi flagging\")\n",
    "\n",
    "# Chunking of Visibility dataset in frequency\n",
    "\n",
    "# Set a number of \"parallel dask tasks\" to divide calibration between\n",
    "#  - There is no dask. Each \"task\" is done sequentially.\n",
    "ndasktask = 4\n",
    "\n",
    "# Averaging of Visibility datasets in time or frequency.\n",
    "#  - Presumably use dask parallelism.\n",
    "#  - Done as part of chunking?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full spectral range: 125.0000 - 125.3402 MHz\n",
      "band spectral range: 125.0000 - 125.0810 MHz (dask task 0, nchan = 16)\n",
      "band spectral range: 125.0864 - 125.1674 MHz (dask task 1, nchan = 16)\n",
      "band spectral range: 125.1728 - 125.2538 MHz (dask task 2, nchan = 16)\n",
      "band spectral range: 125.2592 - 125.3402 MHz (dask task 3, nchan = 16)\n"
     ]
    }
   ],
   "source": [
    "# Predict model visibilities\n",
    "\n",
    "# Could do this inside the bandpass calibration area, parallel by subband.\n",
    "# But keep it separate to test that:\n",
    "#  - it can be done in another workflow (e.g. in pre-processing)\n",
    "#  - accelerators can be used\n",
    "\n",
    "# Create an empty model Visibility dataset\n",
    "#  - Is it better to generate separate sub-band datasets and then concatenate?\n",
    "#     - It is presumably faster to allocate the xarray sub-bands in parallel.\n",
    "#     - If they have frequency chunking anyway, perhaps concat is efficient...\n",
    "#  - Want frequency chuncking, so copy rather than calling create_visibility?\n",
    "#     - Seems reasonable, but may want to duplicate pre-proc time and\n",
    "#       frequency averaging if there is appreciable decorrelation. In which\n",
    "#       case this would need to be done before pre-precessing.\n",
    "modelvis = vis.assign({\"vis\": xarray.zeros_like(vis.vis)})\n",
    "assert np.all(modelvis.vis.data == 0)\n",
    "\n",
    "print(\n",
    "    \"full spectral range: \"\n",
    "    + f\"{np.min(modelvis.frequency.data)/1e6:.4f} - \"\n",
    "    + f\"{np.max(modelvis.frequency.data)/1e6:.4f} MHz\"\n",
    ")\n",
    "\n",
    "nchan = 0\n",
    "for dasktask, slice_lims in enumerate(get_slice_lims(nfrequency, ndasktask)):\n",
    "    # Create an xarray view for the current sub-band\n",
    "    bandmodel = modelvis.isel(frequency=slice(slice_lims[0], slice_lims[1]))\n",
    "    nchan += len(bandmodel.frequency)\n",
    "    print(\n",
    "        \"band spectral range: \"\n",
    "        + f\"{np.min(bandmodel.frequency.data)/1e6:.4f} - \"\n",
    "        + f\"{np.max(bandmodel.frequency.data)/1e6:.4f} MHz \"\n",
    "        + f\"(dask task {dasktask}, nchan = {len(bandmodel.frequency)})\"\n",
    "    )\n",
    "\n",
    "    # Put a point source at phase centre\n",
    "    lsm_components = convert_model_to_skycomponents(\n",
    "        lsm, bandmodel.frequency.data, freq0=200e6\n",
    "    )\n",
    "    bandmodel = predict_from_components(bandmodel, lsm_components, beams=beams)\n",
    "\n",
    "assert len(modelvis.frequency) == nchan\n",
    "\n",
    "# Make sure modelvis was updated\n",
    "#  - i.e. ensure that the isel in predict used reference semantics\n",
    "assert not np.all(\n",
    "    modelvis.vis.data == 0\n",
    "), \"bandmodel view updates should have changed this\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "band spectral range: 125.0000 - 125.0810 MHz (dask task 0, nchan = 16)\n",
      "band spectral range: 125.0864 - 125.1674 MHz (dask task 1, nchan = 16)\n",
      "band spectral range: 125.1728 - 125.2538 MHz (dask task 2, nchan = 16)\n",
      "band spectral range: 125.2592 - 125.3402 MHz (dask task 3, nchan = 16)\n"
     ]
    }
   ],
   "source": [
    "# Do the bandpass calibration\n",
    "\n",
    "# Create a full-band bandpass calibration gain table\n",
    "#  - It may be easier to do this in each sub-band then concatenate...\n",
    "gaintable = create_gaintable_from_visibility(\n",
    "    vis, jones_type=\"B\", timeslice=solution_interval\n",
    ")\n",
    "\n",
    "assert len(gaintable.time) == 1\n",
    "\n",
    "refant = 0\n",
    "\n",
    "for dasktask, slice_lims in enumerate(get_slice_lims(nfrequency, ndasktask)):\n",
    "    # Create xarray views for the current sub-band\n",
    "    bandvis = vis.isel(frequency=slice(slice_lims[0], slice_lims[1]))\n",
    "    bandmodel = modelvis.isel(frequency=slice(slice_lims[0], slice_lims[1]))\n",
    "    # This assumes that the same slicing is used for the table. The solver\n",
    "    # allows for each task to also combine the data into a single solution for\n",
    "    # all channels, to generate solutions at the task sub-band resolution.\n",
    "    # Would need to generalise this selection though.\n",
    "    bandtable = gaintable.isel(frequency=slice(slice_lims[0], slice_lims[1]))\n",
    "    print(\n",
    "        \"band spectral range: \"\n",
    "        + f\"{np.min(bandmodel.frequency.data)/1e6:.4f} - \"\n",
    "        + f\"{np.max(bandmodel.frequency.data)/1e6:.4f} MHz \"\n",
    "        + f\"(dask task {dasktask}, nchan = {len(bandmodel.frequency)})\"\n",
    "    )\n",
    "\n",
    "    # Call bandpass calibration function for this sub-band.\n",
    "    #  - bandtable should either have a single solution spectral channel or\n",
    "    #    one for each input channel. Here it is the latter.\n",
    "    #  - Internally, the bandpass calibration function might call solvers\n",
    "    #    multiple times.\n",
    "    #  - The bandpass calibration function should return a list of bad\n",
    "    #    antennas and bad channels, as well as other QA data.\n",
    "\n",
    "    solve_bandpass(\n",
    "        vis=bandvis,\n",
    "        modelvis=bandmodel,\n",
    "        gain_table=bandtable,\n",
    "        refant=refant,\n",
    "    )\n",
    "\n",
    "# Do some phase referencing for comparisons\n",
    "inputdata = jones.gain.data * np.exp(\n",
    "    -1j * np.angle(jones.gain.data[:, [refant], :, :, :])\n",
    ")\n",
    "\n",
    "assert np.all(np.isclose(gaintable.gain.data, inputdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do post-processing\n",
    "\n",
    "# Do any required interpolation.\n",
    "\n",
    "# Estimate delays using the full GainTable (could distribute over antennas)\n",
    "\n",
    "# Estimate differential Faraday rotation using the full GainTable (could\n",
    "# distribute over antennas)\n",
    "\n",
    "# Generate QA and flagging information"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
