{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee635bb7",
   "metadata": {},
   "source": [
    "# Refactor Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea01b150",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a42a1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "eb_coeffs = \"/home/maneesh/.cache/pypoetry/virtualenvs/ska-sdp-instrumental-calibration-vujiG8jS-py3.10/share/everybeam/\"\n",
    "\n",
    "# sys.path.insert(0, \"/home/maneesh/Work/SKAO/EveryBeam/build/python\")\n",
    "# eb_coeffs = \"/home/maneesh/Work/SKAO/EveryBeam/coeffs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e7fea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import importlib\n",
    "import os\n",
    "import shutil\n",
    "from typing import Literal, Optional, Union\n",
    "\n",
    "import dask\n",
    "import dask.array as da\n",
    "from distributed import Client, LocalCluster, performance_report\n",
    "import everybeam as eb\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import xarray as xr\n",
    "from astropy import constants as const\n",
    "from astropy.coordinates import ITRS, AltAz, SkyCoord\n",
    "from astropy.time import Time\n",
    "from ska_sdp_datamodels.calibration import GainTable\n",
    "from ska_sdp_datamodels.configuration import Configuration\n",
    "from ska_sdp_datamodels.sky_model import SkyComponent\n",
    "from ska_sdp_datamodels.visibility import Visibility\n",
    "from ska_sdp_func_python.imaging.dft import dft_skycomponent_visibility\n",
    "from ska_sdp_instrumental_calibration.data_managers.dask_wrappers import (\n",
    "    predict_vis,\n",
    "    prediction_central_beams,\n",
    "    restore_baselines_dim,\n",
    "    simplify_baselines_dim,\n",
    ")\n",
    "from ska_sdp_instrumental_calibration.data_managers.visibility import (\n",
    "    read_dataset_from_zarr,\n",
    ")\n",
    "from ska_sdp_instrumental_calibration.logger import setup_logger\n",
    "from ska_sdp_instrumental_calibration.processing_tasks.beams import radec_to_xyz\n",
    "from ska_sdp_instrumental_calibration.processing_tasks.lsm import (\n",
    "    Component,\n",
    "    convert_model_to_skycomponents,\n",
    "    generate_lsm_from_csv,\n",
    "    generate_lsm_from_gleamegc,\n",
    ")\n",
    "from ska_sdp_instrumental_calibration.processing_tasks.predict import (\n",
    "    GenericBeams,\n",
    "    dft_skycomponent_local,\n",
    "    gaussian_tapers,\n",
    "    generate_rotation_matrices,\n",
    "    predict_from_components,\n",
    ")\n",
    "from ska_sdp_instrumental_calibration.scheduler import UpstreamOutput\n",
    "from ska_sdp_instrumental_calibration.workflow.stages.load_data import load_data_stage\n",
    "from ska_sdp_instrumental_calibration.workflow.utils import (\n",
    "    create_bandpass_table,\n",
    "    with_chunks,\n",
    ")\n",
    "from xarray.core.utils import Frozen\n",
    "from ska_sdp_instrumental_calibration.workflow.utils import create_solint_slices\n",
    "\n",
    "from ska_sdp_piper.piper.utils.log_util import LogPlugin\n",
    "\n",
    "from ska_sdp_instrumental_calibration.data_managers.dask_wrappers import (\n",
    "    apply_gaintable_to_dataset,\n",
    ")\n",
    "\n",
    "from ska_sdp_datamodels.science_data_model import ReceptorFrame\n",
    "\n",
    "from ska_sdp_instrumental_calibration.workflow.utils import (\n",
    "    get_indices_from_grouped_bins,\n",
    "    get_intervals_from_grouped_bins,\n",
    ")\n",
    "\n",
    "\n",
    "np.random.seed(57)\n",
    "\n",
    "logger = setup_logger(\"predict_ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92db9c4b",
   "metadata": {},
   "source": [
    "## Setup Dask (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72239e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if \"local_cluster\" not in globals():\n",
    "# #     local_cluster = LocalCluster(\n",
    "# #         n_workers=4, threads_per_worker=3, dashboard_address=\":30088\"\n",
    "# #     )\n",
    "\n",
    "# # if \"dask_client\" not in globals():\n",
    "# #     # dask_client = local_cluster.get_client()\n",
    "dask_client = Client(\"localhost:34567\")\n",
    "dask_client.forward_logging()\n",
    "log_configure_plugin = LogPlugin(verbose=False)\n",
    "dask_client.register_plugin(log_configure_plugin)\n",
    "\n",
    "# # print(local_cluster.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8c1c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'dask_client' in globals():\n",
    "#     dask_client.close()\n",
    "#     del dask_client\n",
    "\n",
    "# if 'local_cluster' in globals():\n",
    "#     local_cluster.close()\n",
    "#     del local_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8252ee03",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b20483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_arrays(\n",
    "    actual: np.ndarray,\n",
    "    expected: np.ndarray,\n",
    "    rtol=1e-6,\n",
    "    atol=1e-12,\n",
    "    meta=\"Data\",\n",
    "    output: Literal[\"print\", \"log\", \"raise\"] = \"print\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare two arrays (NumPy or Dask) element-wise with tolerance thresholds.\n",
    "\n",
    "    This function checks absolute and relative differences between two arrays and\n",
    "    reports the maximum absolute difference, maximum relative difference, and the\n",
    "    number and percentage of elements that differ beyond the specified tolerances.\n",
    "\n",
    "    If either input is a Dask array, all required values are finalized in a single\n",
    "    `dask.compute` call to minimize graph execution overhead.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : numpy.ndarray or dask.array.Array\n",
    "        The array containing computed or observed values.\n",
    "    expected : numpy.ndarray or dask.array.Array\n",
    "        The reference array to compare against.\n",
    "    rtol : float, default 1e-6\n",
    "        Relative tolerance.\n",
    "    atol : float, default 1e-12\n",
    "        Absolute tolerance.\n",
    "    meta : str, default \"Data\"\n",
    "        Label used for output messages.\n",
    "    output: str, Literal[\"print\", \"log\", \"raise\"]\n",
    "        Determines how to present the output\n",
    "        print: Prints the comparision message\n",
    "        log: Logs the comparision message\n",
    "        raise: Raises AssertionError if values don't match\n",
    "    \"\"\"\n",
    "    actions = {\n",
    "        \"print\": lambda level, m: print(m),\n",
    "        \"log\": lambda level, m: (\n",
    "            logger.error(m) if level == \"error\" else logger.info(m)\n",
    "        ),\n",
    "        \"raise\": lambda level, m: (\n",
    "            (_ for _ in ()).throw(AssertionError(m)) if level == \"error\" else None\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    is_dask = isinstance(actual, da.Array) or isinstance(expected, da.Array)\n",
    "\n",
    "    if actual.dtype != expected.dtype:\n",
    "        actions[output](\n",
    "            \"info\",\n",
    "            f\"{meta}: dtype mismatch : actual: {actual.dtype}, expected: {expected.dtype}.\\n\"\n",
    "            f\"Comparison may be influenced by different precision.\",\n",
    "        )\n",
    "\n",
    "    diff = actual - expected\n",
    "\n",
    "    abs_diff = np.abs(diff)\n",
    "    abs_diff_max = abs_diff.max()\n",
    "\n",
    "    # element-wise relative difference (safe for expected == 0)\n",
    "    rel_diff = abs_diff / np.maximum(np.abs(expected), 1e-30)\n",
    "    rel_diff_max = rel_diff.max()\n",
    "\n",
    "    # Decide rule for comparision\n",
    "    # diff_mask = (abs_diff > atol) & (rel_diff > rtol) # More permissive\n",
    "    diff_mask = abs_diff > (atol + rtol * np.abs(expected))  # numpy style comparision\n",
    "    num_diff = diff_mask.sum()\n",
    "\n",
    "    if is_dask:\n",
    "        abs_diff_max, rel_diff_max, num_diff = da.compute(\n",
    "            abs_diff_max, rel_diff_max, num_diff\n",
    "        )\n",
    "\n",
    "    total = actual.size\n",
    "\n",
    "    if num_diff > 0:\n",
    "        msg = (\n",
    "            f\"{meta}: do not match for atol={atol}, rtol={rtol}\\n\"\n",
    "            f\"\\tmax abs diff = {abs_diff_max}\\n\"\n",
    "            f\"\\tmax rel diff = {rel_diff_max}\\n\"\n",
    "            f\"\\tdifferent elements: {num_diff} / {total} ({num_diff / total * 100:.6f}%)\"\n",
    "        )\n",
    "        actions[output](\"error\", msg)\n",
    "    else:\n",
    "        msg = f\"{meta}: match within atol={atol}, rtol={rtol}\"\n",
    "        actions[output](\"info\", msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff74638b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_gaintable_from_vis_new(\n",
    "#     vis: Visibility,\n",
    "#     timeslice: Union[float, Literal[\"auto\"], None] = None,\n",
    "#     jones_type: Literal[\"T\", \"G\", \"B\"] = \"T\",\n",
    "# ):\n",
    "#     # TODO: Write full logic\n",
    "#     # Reference the original create_gaintable_from_visibility function\n",
    "\n",
    "#     # TODO: To simplify dask operations,\n",
    "#     # if timeslice is provided such that 1 < len(solution_time) < len(vis.time)\n",
    "#     # then still the gaintable must have len(solution_time) = len(vis.time)\n",
    "#     # where the solution_time values are duplicated\n",
    "#     # this can be optimized in the future\n",
    "\n",
    "#     gaintable = create_bandpass_table(vis)\n",
    "#     # Since its bandpass table, single interval contains whole time chunk\n",
    "#     gaintable.attrs[\"soln_interval_slices\"] = create_solint_slices(\n",
    "#         vis.time, timeslice, True\n",
    "#     )\n",
    "\n",
    "#     # This should be part of the dim creation logic itself\n",
    "#     gaintable = gaintable.rename(time=\"solution_time\", frequency=\"solution_frequency\")\n",
    "\n",
    "#     # # Following chunking logics should be part of the data creation logic itself\n",
    "#     # This is when we are sure that rest of the code can handle different solutions times\n",
    "#     gaintable = gaintable.chunk({\"solution_time\": 1})\n",
    "\n",
    "#     # if gaintable.jones_type == \"B\":\n",
    "#     if gaintable.solution_frequency.size == vis.frequency.size:\n",
    "#         gaintable = gaintable.chunk({\"solution_frequency\": vis.chunksizes[\"frequency\"]})\n",
    "\n",
    "#     return gaintable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a680fa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test for the new gain interval logic\n",
    "# time_diff = np.diff(vis.time.data)[0]\n",
    "\n",
    "# # Full time in single timeslice\n",
    "# timeslice = np.max(vis.time) - np.min(vis.time)\n",
    "\n",
    "# gain_time_bins = create_solint_slices(vis.time, timeslice, False)\n",
    "# gain_time = gain_time_bins.mean().data\n",
    "\n",
    "# gain_interval = get_intervals_from_grouped_bins(gain_time_bins)\n",
    "\n",
    "\n",
    "# idx = 0\n",
    "# time = gain_time[idx]\n",
    "\n",
    "# time_slice = {\n",
    "#         \"time\": slice(\n",
    "#             time - gain_interval[idx] / 2,\n",
    "#             time + gain_interval[idx] / 2,\n",
    "#         )\n",
    "#     }\n",
    "\n",
    "# assert np.all(vis.time.sel(time_slice).data == vis.time.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de70328f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gaintable_from_vis_new(\n",
    "    vis: Visibility,\n",
    "    timeslice: Union[float, Literal[\"auto\"], None] = None,\n",
    "    jones_type: Literal[\"T\", \"G\", \"B\"] = \"T\",\n",
    "    lower_precision: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Similar behavior as create_gaintable_from_vis, except\n",
    "    1. Creates dask backed data variables\n",
    "    2. Ability to toggle precision of the data variables, currently between 4 or 8 bytes\n",
    "    \"\"\"\n",
    "    # Backward compatibility\n",
    "    if timeslice == \"auto\":\n",
    "        timeslice = None\n",
    "    # TODO: review this time slice creation logic\n",
    "    gain_time_bins = create_solint_slices(vis.time, timeslice, False)\n",
    "    gain_time = gain_time_bins.mean().data\n",
    "    gain_interval = get_intervals_from_grouped_bins(gain_time_bins)\n",
    "    ntimes = len(gain_time)\n",
    "\n",
    "    nants = vis.visibility_acc.nants\n",
    "\n",
    "    # Set the frequency sampling\n",
    "    if jones_type == \"B\":\n",
    "        gain_frequency = vis.frequency.data\n",
    "        nfrequency = len(gain_frequency)\n",
    "    elif jones_type in (\"G\", \"T\"):\n",
    "        gain_frequency = np.mean(vis.frequency.data, keepdims=True)\n",
    "        nfrequency = 1\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown Jones type {jones_type}\")\n",
    "\n",
    "    # There is only one receptor frame in Visibility\n",
    "    # Use it for both receptor1 and receptor2\n",
    "    receptor_frame = ReceptorFrame(vis.visibility_acc.polarisation_frame.type)\n",
    "    nrec = receptor_frame.nrec\n",
    "\n",
    "    gain_shape = [ntimes, nants, nfrequency, nrec, nrec]\n",
    "\n",
    "    # Create dask backed data variables\n",
    "    comp_dtype, fl_dtype = np.complex128, np.float64\n",
    "    if lower_precision:\n",
    "        comp_dtype, fl_dtype = np.complex64, np.float32\n",
    "\n",
    "    gain = da.broadcast_to(da.eye(nrec, dtype=comp_dtype), gain_shape)\n",
    "    gain_weight = da.ones(gain_shape, dtype=fl_dtype)\n",
    "    gain_residual = da.zeros([ntimes, nfrequency, nrec, nrec], dtype=fl_dtype)\n",
    "\n",
    "    gain_table = GainTable.constructor(\n",
    "        gain=gain,\n",
    "        time=gain_time,\n",
    "        interval=gain_interval,\n",
    "        weight=gain_weight,\n",
    "        residual=gain_residual,\n",
    "        frequency=gain_frequency,\n",
    "        receptor_frame=receptor_frame,\n",
    "        phasecentre=vis.phasecentre,\n",
    "        configuration=vis.configuration,\n",
    "        jones_type=jones_type,\n",
    "    )\n",
    "\n",
    "    # Rename dimensions to be more explicity about their usage\n",
    "    gain_table = gain_table.rename(time=\"solution_time\", frequency=\"solution_frequency\")\n",
    "\n",
    "    # Chunk data variables\n",
    "    gain_table = gain_table.chunk({\"solution_time\": 1})\n",
    "    if gain_table.solution_frequency.size == vis.frequency.size:\n",
    "        gain_table = gain_table.chunk(\n",
    "            {\"solution_frequency\": vis.chunksizes[\"frequency\"]}\n",
    "        )\n",
    "\n",
    "    # Logic duplicated from create_solint_slices\n",
    "    gain_table.attrs[\"soln_interval_slices\"] = get_indices_from_grouped_bins(\n",
    "        gain_time_bins\n",
    "    )\n",
    "\n",
    "    return gain_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34d56a8",
   "metadata": {},
   "source": [
    "## Setup inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179bcf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ms_path = \"/home/ska/Work/data/INST/lg3/cal_bpp_vis-lg3-rotated.small.ms\"\n",
    "# input_ms_path = \"/home/ska/Work/data/INST/lg3/cal_bpp_vis-lg3-rotated.ms\"\n",
    "# input_ms_path = \"/home/maneesh/Work/SKAO/ska-sdp-instrumental-calibration/data/demo.ms\"\n",
    "\n",
    "vis_cache_dir = \"/home/maneesh/Work/SKAO/ska-sdp-instrumental-calibration/cache\"\n",
    "\n",
    "# eb_ms = \"/home/ska/Work/data/INST/sim/OSKAR_MOCK.ms\"\n",
    "eb_ms = input_ms_path\n",
    "\n",
    "lsm_csv_path = \"/home/ska/Work/data/INST/lg3/sky_model_cal.csv\"\n",
    "gleamfile = \"/home/ska/Work/data/INST/sim/gleamegc.dat\"\n",
    "\n",
    "fov = 10.0\n",
    "flux_limit = 1.0\n",
    "alpha0 = -0.78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58ef4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "upstream_output = UpstreamOutput()\n",
    "\n",
    "nchannels_per_chunk = 64\n",
    "ntimes_per_ms_chunk = 16\n",
    "\n",
    "upstream_output = load_data_stage.stage_definition(\n",
    "    upstream_output,\n",
    "    nchannels_per_chunk,\n",
    "    ntimes_per_ms_chunk,\n",
    "    vis_cache_dir,\n",
    "    False,\n",
    "    \"DATA\",\n",
    "    0,\n",
    "    0,\n",
    "    # None, # NOTE: DHR-338\n",
    "    # None, # NOTE: DHR-338\n",
    "    # None, # NOTE: DHR-338\n",
    "    {\"input\": input_ms_path},\n",
    "    \".\",\n",
    ")\n",
    "vis = upstream_output.vis\n",
    "\n",
    "# vis = read_dataset_from_zarr(\"/home/maneesh/Work/SKAO/ska-sdp-instrumental-calibration/dhr_338cache/cal_bpp_vis-lg3-rotated.small.ms_fid0_ddid0\", {})\n",
    "\n",
    "# NOTE: DHR-338\n",
    "# Explcitly load it, in case its a dask array\n",
    "vis.antenna1.load()\n",
    "vis.antenna2.load()\n",
    "\n",
    "timeslice = np.max(vis.time.data) - np.min(vis.time.data)\n",
    "gaintable = create_gaintable_from_vis_new(\n",
    "    vis, timeslice=timeslice, jones_type=\"B\", lower_precision=True\n",
    ")\n",
    "\n",
    "lsm = generate_lsm_from_gleamegc(\n",
    "    gleamfile=gleamfile,\n",
    "    phasecentre=vis.phasecentre,\n",
    "    fov=fov,\n",
    "    flux_limit=flux_limit,\n",
    "    alpha0=alpha0,\n",
    ")\n",
    "\n",
    "# lsm = generate_lsm_from_csv(\n",
    "#     csvfile=lsm_csv_path,\n",
    "#     phasecentre=vis.phasecentre,\n",
    "#     fov=fov,\n",
    "#     flux_limit=flux_limit,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6320c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_type = \"everybeam\"\n",
    "# beam_type = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce7d19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_rm = da.from_array(np.random.rand(gaintable.antenna.size))\n",
    "station_rm_xdr = xr.DataArray(\n",
    "    station_rm, name=\"station_rm\", coords={\"antenna\": gaintable.antenna}\n",
    ")\n",
    "\n",
    "# station_rm = None\n",
    "# station_rm_xdr = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e978ccbe",
   "metadata": {},
   "source": [
    "## Generate Rotation Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ec7b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rotation_matrices_new(\n",
    "    rm: np.ndarray,\n",
    "    frequency: np.ndarray,\n",
    "    output_dtype: type = np.complex64,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Generate station rotation matrix from RM values.\n",
    "\n",
    "    :param rm: 1D array of rotation measure values [nstation].\n",
    "    :param frequency: 1D array of frequency values [nfrequency].\n",
    "    :param output_dtype: output dtype of rotation matrix\n",
    "\n",
    "    :return: 4D array of rotation matrix: [nstation, nfrequency, 2, 2].\n",
    "    \"\"\"\n",
    "    lambda_sq = np.power((const.c.value / frequency), 2)\n",
    "\n",
    "    phi = rm[..., np.newaxis] * lambda_sq\n",
    "\n",
    "    cos_val = np.cos(phi)\n",
    "    sin_val = np.sin(phi)\n",
    "\n",
    "    I = np.array([[1, 0], [0, 1]])\n",
    "    A = np.array([[0, -1], [1, 0]])\n",
    "\n",
    "    rot_array = (\n",
    "        cos_val[:, :, np.newaxis, np.newaxis] * I\n",
    "        + sin_val[:, :, np.newaxis, np.newaxis] * A\n",
    "    )\n",
    "\n",
    "    return rot_array.astype(output_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d570de0b",
   "metadata": {},
   "source": [
    "## Generic Beams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cd814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointingBelowHorizon(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class BeamsLow:\n",
    "    \"\"\"A beam class specific to handling low beams.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        configuration: Configuration,\n",
    "        direction: SkyCoord,\n",
    "        frequency: np.ndarray,\n",
    "        ms_path: str,\n",
    "        soln_time: np.ndarray | float,\n",
    "    ):\n",
    "        self.nstations = configuration.id.size\n",
    "        self.array_location = configuration.location\n",
    "        self.beam_direction = direction\n",
    "        self.frequency = frequency\n",
    "        self.beam_ms = ms_path\n",
    "\n",
    "        self.delay_dir_itrf = None\n",
    "        self.telescope = None\n",
    "        self.scale = None\n",
    "\n",
    "        self.solution_time = self.convert_time_to_solution_time(soln_time)\n",
    "        # NOTE: HACK: Uncomment below line, and run the pipeline\n",
    "        # as a check to remove subtle floating point differences\n",
    "        # between datetime64 and mjd time values\n",
    "        # self.solution_time = np.mean(self.convert_time_to_solution_time(vis.time.data), keepdims=True)\n",
    "\n",
    "        self.solution_time_mjd_seconds = self.solution_time.mjd * 86400\n",
    "\n",
    "        # Check beam pointing direction for all solution times\n",
    "        self.validate_direction(self.beam_direction)\n",
    "\n",
    "        # Coordinates of beam centre\n",
    "        self.delay_dir_itrf = np.array(\n",
    "            [\n",
    "                radec_to_xyz(self.beam_direction, self.solution_time[time_idx])\n",
    "                for time_idx in range(self.solution_time.size)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.telescope = eb.load_telescope(self.beam_ms)\n",
    "\n",
    "        self.scale = np.ones(\n",
    "            (self.solution_time.size, self.frequency.size), dtype=self.frequency.dtype\n",
    "        )\n",
    "        if type(self.telescope) is eb.OSKAR:\n",
    "            \"\"\"\n",
    "            Set normalisation scaling to the Frobenius norm of the zenith\n",
    "            response divided by sqrt(2).\n",
    "            Should be the same for all stations so pick one. Should use the\n",
    "            station location rather than central array location, e.g. using\n",
    "            the following code, but some functions (e.g. ska-sdp-datamodels\n",
    "            function create_named_configuration -- at least for some\n",
    "            configurations) set xyz coordinates to ENU rather than the\n",
    "            geocentric coordinates. So use the array location and a central\n",
    "            station for now. Note that OSKAR datasets have correct geocentric\n",
    "            coordinates, but also have the array location set to the first\n",
    "            station xyz, so using array_location with stn=0 works.\n",
    "                xyz = vis.configuration.xyz.data[stn, :]\n",
    "                self.antenna_locations.append(\n",
    "                    EarthLocation.from_geocentric(\n",
    "                        xyz[0], xyz[1], xyz[2], unit=\"m\",\n",
    "                    )\n",
    "                )\n",
    "            \"\"\"\n",
    "            logger.info(\"Setting beam normalisation for OSKAR data\")\n",
    "\n",
    "            stn = 0\n",
    "            for time_idx in range(self.solution_time.size):\n",
    "                dir_itrf_zen = radec_to_xyz(\n",
    "                    SkyCoord(\n",
    "                        alt=90,\n",
    "                        az=0,\n",
    "                        unit=\"deg\",\n",
    "                        frame=\"altaz\",\n",
    "                        obstime=self.solution_time[time_idx],\n",
    "                        location=self.array_location,\n",
    "                    ),\n",
    "                    self.solution_time[time_idx],\n",
    "                )\n",
    "\n",
    "                for chan, freq in enumerate(self.frequency):\n",
    "                    J = self.telescope.station_response(\n",
    "                        self.solution_time_mjd_seconds[time_idx],\n",
    "                        stn,\n",
    "                        freq,\n",
    "                        dir_itrf_zen,\n",
    "                        dir_itrf_zen,\n",
    "                    )\n",
    "                    self.scale[time_idx, chan] = np.sqrt(2) / np.linalg.norm(J)\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_time_to_solution_time(time: float | np.ndarray) -> Time:\n",
    "        \"\"\"\n",
    "        :return Time object containing an array of time values\n",
    "        \"\"\"\n",
    "        # This Time->Time conversion is what was originally done in INST\n",
    "        # Although Time can be treated as a \"Value Object\", there are subtle\n",
    "        # differences in the order in which floating point operations are performed\n",
    "        # thus the results may slightly vary if you try to simplify this\n",
    "        # By removeing the additional datetime64 to time conversion\n",
    "        solution_time = Time(Time(time / 86400.0, format=\"mjd\", scale=\"utc\").datetime64)\n",
    "        return Time([solution_time]) if solution_time.isscalar else solution_time\n",
    "\n",
    "    def validate_direction(self, direction: SkyCoord) -> AltAz:\n",
    "        \"\"\"\n",
    "        Calculate Altitude-Azimuth for a direction, and ensure that the\n",
    "        direction is valid for the given solution interval of the beam\n",
    "\n",
    "        raises PointingBelowHorizon exception if direction is below horizon\n",
    "\n",
    "        :return Altaz[list] if direction is valid\n",
    "        \"\"\"\n",
    "        altaz = direction.transform_to(\n",
    "            AltAz(obstime=self.solution_time, location=self.array_location)\n",
    "        )\n",
    "        # Since self.solution_time is always an Time[list], altaz will also be a AltAz[list]\n",
    "        if (altaz.alt.degree < 0).any():\n",
    "            # TODO: More verbose error\n",
    "            raise PointingBelowHorizon(\n",
    "                f\"Pointing below horizon for some of the solution times\"\n",
    "            )\n",
    "        return altaz\n",
    "\n",
    "    def array_response(\n",
    "        self,\n",
    "        direction: SkyCoord,\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Return the response of each antenna or station in a given direction\n",
    "\n",
    "        :param direction: Direction of desired response\n",
    "        :return: np.complex128 array of beam matrices [soln_time, nant, nfreq, 2, 2]\n",
    "        \"\"\"\n",
    "        # Get the component direction in ITRF\n",
    "        dir_itrf = np.array(\n",
    "            [\n",
    "                radec_to_xyz(direction, self.solution_time[time_idx])\n",
    "                for time_idx in range(self.solution_time.size)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        beams = np.empty(\n",
    "            (self.solution_time.size, self.nstations, self.frequency.size, 2, 2),\n",
    "            dtype=np.complex128,\n",
    "        )\n",
    "\n",
    "        for time_idx in range(self.solution_time.size):\n",
    "            for stn in range(self.nstations):\n",
    "                for chan, freq in enumerate(self.frequency):\n",
    "                    beams[time_idx, stn, chan, :, :] = (\n",
    "                        self.telescope.station_response(\n",
    "                            self.solution_time_mjd_seconds[time_idx],\n",
    "                            stn,\n",
    "                            freq,\n",
    "                            dir_itrf[time_idx],\n",
    "                            self.delay_dir_itrf[time_idx],\n",
    "                        )\n",
    "                        * self.scale[time_idx, chan]\n",
    "                    )\n",
    "\n",
    "        return beams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc84fa4d",
   "metadata": {},
   "source": [
    "## DFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789eda24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_tapers_new(\n",
    "    u: np.ndarray,\n",
    "    v: np.ndarray,\n",
    "    params: dict[float],\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Calculated visibility amplitude tapers for Gaussian components.\n",
    "\n",
    "    Note: this needs to be tested. Generate, image and fit a model component?\n",
    "    \"\"\"\n",
    "    # exp(-a*x^2) transforms to exp(-pi^2*u^2/a)\n",
    "    # a = 4log(2)/FWHM^2 so scaling = pi^2 * FWHM^2 / (4log(2))\n",
    "    scale = -(np.pi * np.pi) / (4 * np.log(2.0))\n",
    "    # Rotate baselines to the major/minor axes:\n",
    "    bpa = params[\"bpa\"] * np.pi / 180\n",
    "    bmaj = params[\"bmaj\"] * np.pi / 180\n",
    "    bmin = params[\"bmin\"] * np.pi / 180\n",
    "\n",
    "    up = np.cos(bpa) * u + np.sin(bpa) * v\n",
    "    vp = -np.sin(bpa) * u + np.cos(bpa) * v\n",
    "\n",
    "    return np.exp((bmaj * bmaj * up * up + bmin * bmin * vp * vp) * scale)\n",
    "\n",
    "\n",
    "def dft_skycomponent_new(\n",
    "    uvw: np.ndarray,\n",
    "    skycomponent: SkyComponent,\n",
    "    phase_centre: SkyCoord,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    uvw: (time, baselineid, spatial)\n",
    "    skycomponent.frequency: (frequency,)\n",
    "    skycomponent.flux: (frequency, polarisation)\n",
    "\n",
    "    returns: (time, baselineid, frequency, polarisation)\n",
    "    \"\"\"\n",
    "\n",
    "    scaled_uvw = np.einsum(\n",
    "        \"tbs,f->tbfs\",\n",
    "        uvw,\n",
    "        skycomponent.frequency / const.c.value,  # pylint: disable=no-member\n",
    "    )\n",
    "    scaled_u = scaled_uvw[..., 0]\n",
    "    scaled_v = scaled_uvw[..., 1]\n",
    "    scaled_w = scaled_uvw[..., 2]\n",
    "\n",
    "    # Get coordaintes of phase centre\n",
    "    ra0 = phase_centre.ra.radian\n",
    "    cdec0 = np.cos(phase_centre.dec.radian)\n",
    "    sdec0 = np.sin(phase_centre.dec.radian)\n",
    "\n",
    "    cdec = np.cos(skycomponent.direction.dec.radian)\n",
    "    sdec = np.sin(skycomponent.direction.dec.radian)\n",
    "    cdra = np.cos(skycomponent.direction.ra.radian - ra0)\n",
    "    l_comp = cdec * np.sin(skycomponent.direction.ra.radian - ra0)\n",
    "    m_comp = sdec * cdec0 - cdec * sdec0 * cdra\n",
    "    n_comp = sdec * sdec0 + cdec * cdec0 * cdra\n",
    "\n",
    "    comp_data = np.exp(\n",
    "        -2j * np.pi * (scaled_u * l_comp + scaled_v * m_comp + scaled_w * (n_comp - 1))\n",
    "    )\n",
    "\n",
    "    if skycomponent.shape == \"GAUSSIAN\":\n",
    "        comp_data = comp_data * gaussian_tapers_new(\n",
    "            scaled_u, scaled_v, skycomponent.params\n",
    "        )\n",
    "\n",
    "    return np.einsum(\n",
    "        \"tbf,fp->tbfp\",\n",
    "        comp_data,\n",
    "        skycomponent.flux,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d1b720",
   "metadata": {},
   "source": [
    "## Predict from components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453c9f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_antenna_gains_to_visibility(vis, gains, antenna1, antenna2, inverse=False):\n",
    "    \"\"\"\n",
    "    vis: (time, baselineid, frequency, polarisation)\n",
    "    gains: (time, antennas, frequency, nrec1, nrec2)\n",
    "    antenna1: (baselineid)\n",
    "        Indices of the antenna1 in all baseline pairs\n",
    "    antenna2: (baselineid)\n",
    "        Indices of the antenna2 in all baseline pairs\n",
    "    inverse: bool\n",
    "        Whether to inverse the gains before applying\n",
    "    \"\"\"\n",
    "    if inverse:\n",
    "        gains = np.linalg.pinv(gains)\n",
    "\n",
    "    vis_old_shape = vis.shape\n",
    "    vis_new_shape = vis.shape[:3] + (2, 2)\n",
    "\n",
    "    return np.einsum(  # pylint: disable=too-many-function-args\n",
    "        \"tbfpx,tbfxy,tbfqy->tbfpq\",\n",
    "        gains[:, antenna1, ...],\n",
    "        vis.reshape(vis_new_shape),\n",
    "        gains[:, antenna2, ...].conj(),\n",
    "    ).reshape(vis_old_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071c6f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_components_new(\n",
    "    uvw: np.ndarray,\n",
    "    frequency: np.ndarray,\n",
    "    polarisation: np.ndarray,\n",
    "    antenna1: np.ndarray,\n",
    "    antenna2: np.ndarray,\n",
    "    configuration: Configuration,\n",
    "    phasecentre: SkyCoord,\n",
    "    lsm: list[Component],\n",
    "    beam_type: Optional[str] = \"everybeam\",\n",
    "    eb_coeffs: Optional[str] = None,\n",
    "    eb_ms: Optional[str] = None,\n",
    "    soln_time: float = None,\n",
    "    station_rm: np.ndarray = None,\n",
    "    output_dtype: type = np.complex64,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Predict model visibilities from a Component List.\n",
    "\n",
    "    :param uvw: (time, baselineid, spatial)\n",
    "    :param frequency: (frequency,)\n",
    "    :param polarisation: (polarisation,)\n",
    "    :param antenna1: (nant,)\n",
    "    :param antenna2: (nant,)\n",
    "    :param configuration: object\n",
    "    :param phasecentre: object\n",
    "    :param lsm: Component List containing the local sky model\n",
    "    :param beam_type: str\n",
    "        Type of beam model to use. Default is \"everybeam\". If set\n",
    "        to None, no beam will be applied.\n",
    "    :param eb_coeffs: str\n",
    "        Everybeam coeffs datadir containing beam coefficients.\n",
    "        Required if beam_type is \"everybeam\".\n",
    "    :param eb_ms: str\n",
    "        Measurement set need to initialise the everybeam telescope.\n",
    "        Required if beam_type is \"everybeam\".\n",
    "    :param soln_time: float\n",
    "        \"Solution time\" value of the gain solution. Used for initialising Beams\n",
    "        for that current time slice. Required if beam_type is \"everybeam\".\n",
    "        Must be a single time value.\n",
    "    :param station_rm: (nant,)\n",
    "        Station rotation measure values. Default is None.\n",
    "    :param output_dtype: Type\n",
    "\n",
    "\n",
    "    returns: (time, baselineid, frequency, polarisation)\n",
    "    \"\"\"\n",
    "    skycomponents = convert_model_to_skycomponents(lsm, frequency)\n",
    "    # TODO: Do this check outside when we compute lsm\n",
    "    # if len(skycomponents) == 0:\n",
    "    #     logger.warning(\"No sky model components to predict\")\n",
    "    #     return\n",
    "    # TODO : Do these checks outside\n",
    "    # if len(station_rm) != len(configuration.id):\n",
    "    #     raise ValueError(\"unexpected length for station_rm\")\n",
    "\n",
    "    # Set up the beam model\n",
    "    if beam_type == \"everybeam\":\n",
    "        logger.info(\"Using EveryBeam model in predict\")\n",
    "        if eb_coeffs is None or eb_ms is None:\n",
    "            raise ValueError(\"eb_coeffs and eb_ms required for everybeam\")\n",
    "\n",
    "        if soln_time is None:\n",
    "            raise ValueError(\"solution time must be provided for Beam calculation\")\n",
    "\n",
    "        # Could do this once externally, but don't want to pass around\n",
    "        # exotic data types.\n",
    "        os.environ[\"EVERYBEAM_DATADIR\"] = eb_coeffs\n",
    "\n",
    "        beams = BeamsLow(\n",
    "            configuration=configuration,\n",
    "            direction=phasecentre,\n",
    "            frequency=frequency,\n",
    "            ms_path=eb_ms,\n",
    "            soln_time=soln_time,\n",
    "        )\n",
    "    else:\n",
    "        logger.info(\"No beam model used in predict\")\n",
    "\n",
    "    # Set up the Faraday rotation model\n",
    "    faraday_rot_matrix = None\n",
    "    if station_rm is not None:\n",
    "        faraday_rot_matrix = generate_rotation_matrices_new(\n",
    "            station_rm, frequency, output_dtype\n",
    "        )[\n",
    "            np.newaxis, ...\n",
    "        ]  # Add time axis at the start\n",
    "\n",
    "    predicted_vis = np.zeros(\n",
    "        (*uvw.shape[:2], frequency.size, polarisation.size), dtype=output_dtype\n",
    "    )\n",
    "\n",
    "    for comp in skycomponents:\n",
    "        effective_antenna_response = None\n",
    "        theta = 0\n",
    "\n",
    "        # Apply beam distortions and add to combined model visibilities\n",
    "        if beam_type == \"everybeam\":\n",
    "            # Check component direction\n",
    "            try:\n",
    "                altaz = beams.validate_direction(comp.direction)[0]\n",
    "            except PointingBelowHorizon:\n",
    "                logger.warning(\"LSM component [%s] below horizon\", comp.name)\n",
    "                continue\n",
    "\n",
    "            theta = np.pi / 2 - altaz.alt.radian\n",
    "\n",
    "            # NOTE: This ID mapping will not always work when the eb_ms file is\n",
    "            # different. Should restrict the form of the eb_ms files allowed,\n",
    "            # or preferably deprecate the eb_ms option.\n",
    "            component_array_response = beams.array_response(direction=comp.direction)[\n",
    "                :, configuration.id\n",
    "            ]\n",
    "\n",
    "            if faraday_rot_matrix is not None:\n",
    "                effective_antenna_response = (\n",
    "                    component_array_response @ faraday_rot_matrix\n",
    "                )\n",
    "            else:\n",
    "                effective_antenna_response = component_array_response\n",
    "        else:\n",
    "            effective_antenna_response = faraday_rot_matrix\n",
    "\n",
    "        sky_comp_vis = dft_skycomponent_new(\n",
    "            uvw=uvw, skycomponent=comp, phase_centre=phasecentre\n",
    "        )\n",
    "\n",
    "        if effective_antenna_response is not None:\n",
    "            sky_comp_vis = apply_antenna_gains_to_visibility(\n",
    "                sky_comp_vis,\n",
    "                effective_antenna_response,\n",
    "                antenna1,\n",
    "                antenna2,\n",
    "            )  # * (np.cos(theta) ** 2) # NOTE: DHR-338\n",
    "\n",
    "        predicted_vis = predicted_vis + sky_comp_vis\n",
    "\n",
    "    return predicted_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb0ef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_sanitize(data: np.ndarray) -> np.ndarray | None:\n",
    "    if (data == None).any():\n",
    "        return None\n",
    "    return data\n",
    "\n",
    "\n",
    "def _predict_from_components_ufunc(\n",
    "    uvw: np.ndarray,\n",
    "    frequency: np.ndarray,\n",
    "    station_rm: np.ndarray | None,\n",
    "    polarisation: np.ndarray,\n",
    "    antenna1: np.ndarray,\n",
    "    antenna2: np.ndarray,\n",
    "    configuration: Configuration,\n",
    "    phasecentre: SkyCoord,\n",
    "    lsm: list[Component],\n",
    "    beam_type: Optional[str] = \"everybeam\",\n",
    "    eb_coeffs: Optional[str] = None,\n",
    "    eb_ms: Optional[str] = None,\n",
    "    soln_time: float = None,\n",
    "    output_dtype: type = np.complex64,\n",
    "):\n",
    "    \"\"\"\n",
    "    A helper function which bridges the gap between\n",
    "    predict_from_components_new and predict_vis_new functions\n",
    "\n",
    "    :param uvw: (time, frequency, baselineid, spatial)\n",
    "    :param frequency: (frequency,)\n",
    "    :param station_rm: (nant,) or None\n",
    "    :param polarisation: (polarisation,)\n",
    "    :param antenna1: (nant,)\n",
    "    :param antenna2: (nant,)\n",
    "    :param configuration: object\n",
    "    :param phasecentre: object\n",
    "    :param lsm: Component List containing the local sky model\n",
    "    :param beam_type: str\n",
    "        Type of beam model to use. Default is \"everybeam\". If set\n",
    "        to None, no beam will be applied.\n",
    "    :param eb_coeffs: str\n",
    "        Everybeam coeffs datadir containing beam coefficients.\n",
    "        Required if beam_type is \"everybeam\".\n",
    "    :param eb_ms: str\n",
    "        Measurement set need to initialise the everybeam telescope.\n",
    "        Required if beam_type is \"everybeam\".\n",
    "    :param soln_time: float\n",
    "        \"Solution time\" value of the gain solution. Used for initialising Beams\n",
    "        for that current time slice. Required if beam_type is \"everybeam\".\n",
    "        Must be a single time value.\n",
    "    :param output_dtype: Type\n",
    "\n",
    "    returns: (time, frequency, baselineid, polarisation)\n",
    "    \"\"\"\n",
    "    # Need to remove extra frequency dimension from uvw\n",
    "    uvw = uvw.squeeze()\n",
    "\n",
    "    return predict_from_components_new(\n",
    "        uvw,\n",
    "        frequency,\n",
    "        polarisation,\n",
    "        antenna1,\n",
    "        antenna2,\n",
    "        configuration,\n",
    "        phasecentre,\n",
    "        lsm,\n",
    "        beam_type=beam_type,\n",
    "        eb_coeffs=eb_coeffs,\n",
    "        eb_ms=eb_ms,\n",
    "        soln_time=soln_time,\n",
    "        station_rm=station_rm,\n",
    "        output_dtype=output_dtype,\n",
    "    ).transpose(\n",
    "        0, 2, 1, 3  #  time, frequency, baselineid, polarisation\n",
    "    )\n",
    "\n",
    "\n",
    "def predict_vis_new(\n",
    "    vis: xr.Dataset,\n",
    "    lsm: list,\n",
    "    beam_type: Optional[str] = \"everybeam\",\n",
    "    eb_ms: Optional[str] = None,\n",
    "    eb_coeffs: Optional[str] = None,\n",
    "    gaintable: GainTable = None,\n",
    "    station_rm: xr.DataArray = None,\n",
    ") -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Distributed Visibility predict.\n",
    "    Supports chunking across frequency and time.\n",
    "\n",
    "    :param vis: Visibility dataset containing observed data to be modelled.\n",
    "        Should be chunked in frequency.\n",
    "    :param lsm: List of LSM components. This is an intermediate format between\n",
    "        the GSM and the evaluated SkyComponent list.\n",
    "    :param beam_type: Type of beam model to use. Default is \"everybeam\".\n",
    "    :param eb_ms: Pathname of Everybeam mock Measurement Set.\n",
    "    :param eb_coeffs: Path to Everybeam coeffs directory.\n",
    "    :param station_rm: Station rotation measure values. Default is None.\n",
    "    :return: Predicted Visibility dataset\n",
    "    \"\"\"\n",
    "    common_input_args = []\n",
    "    common_input_core_dims = []\n",
    "\n",
    "    input_kwargs = dict(\n",
    "        polarisation=vis.polarisation,\n",
    "        antenna1=vis.antenna1,\n",
    "        antenna2=vis.antenna2,\n",
    "        configuration=vis.configuration,\n",
    "        phasecentre=vis.phasecentre,\n",
    "        lsm=lsm,\n",
    "        beam_type=beam_type,\n",
    "        eb_coeffs=eb_coeffs,\n",
    "        eb_ms=eb_ms,\n",
    "        output_dtype=vis.vis.dtype,\n",
    "    )\n",
    "\n",
    "    # Process frequency\n",
    "    # Convert frequency to a chunked dask array\n",
    "    frequency_xdr = xr.DataArray(vis.frequency, name=\"frequency_xdr\").pipe(\n",
    "        with_chunks, vis.chunksizes\n",
    "    )\n",
    "    common_input_args.append(frequency_xdr)\n",
    "    common_input_core_dims.append([])\n",
    "\n",
    "    # Process station_rm\n",
    "    if station_rm is not None:\n",
    "        # Ensure that it is not chunked across any dim\n",
    "        # It can still be a dask array\n",
    "        station_rm = station_rm.chunk(-1)\n",
    "        common_input_args.append(station_rm)\n",
    "        common_input_core_dims.append(list(station_rm.dims))\n",
    "    else:\n",
    "        input_kwargs[\"station_rm\"] = None\n",
    "\n",
    "    # Process beam related parameters\n",
    "    if beam_type == \"everybeam\":\n",
    "        # Do validations early on\n",
    "        if any(x is None for x in (gaintable, eb_ms, eb_coeffs)):\n",
    "            raise ValueError(\n",
    "                \"gaintable, eb_ms and eb_coeffs must be provided \"\n",
    "                \"for beam_type = everybeam\"\n",
    "            )\n",
    "        soln_time = gaintable.solution_time.data\n",
    "        soln_interval_slices = gaintable.soln_interval_slices\n",
    "        assert len(soln_interval_slices) == len(soln_time)\n",
    "    else:\n",
    "        # Set appropriate values so that predict function succeeds\n",
    "        soln_time = [None]\n",
    "        soln_interval_slices = [slice(0, vis.time.size + 1, 1)]\n",
    "\n",
    "    # Call predict ufunc, once per solution interval\n",
    "    predicted_across_soln_time = []\n",
    "    for idx, slc in enumerate(soln_interval_slices):\n",
    "        predicted_per_soln_time: xr.DataArray = xr.apply_ufunc(\n",
    "            _predict_from_components_ufunc,\n",
    "            vis.uvw.isel(time=slc),\n",
    "            *common_input_args,\n",
    "            input_core_dims=[\n",
    "                [\"baselineid\", \"spatial\"],\n",
    "                *common_input_core_dims,\n",
    "            ],\n",
    "            output_core_dims=[\n",
    "                [\"baselineid\", \"polarisation\"],\n",
    "            ],\n",
    "            dask=\"parallelized\",\n",
    "            output_dtypes=[vis.vis.dtype],\n",
    "            dask_gufunc_kwargs=dict(\n",
    "                output_sizes={\n",
    "                    \"baselineid\": vis.baselineid.size,\n",
    "                    \"polarisation\": vis.polarisation.size,\n",
    "                }\n",
    "            ),\n",
    "            kwargs=dict(\n",
    "                **input_kwargs,\n",
    "                soln_time=soln_time[idx],\n",
    "            ),\n",
    "        )\n",
    "        predicted_per_soln_time = predicted_per_soln_time.transpose(\n",
    "            \"time\", \"baselineid\", \"frequency\", \"polarisation\"\n",
    "        )\n",
    "        predicted_across_soln_time.append(predicted_per_soln_time)\n",
    "\n",
    "    predicted: xr.DataArray = xr.concat(predicted_across_soln_time, dim=\"time\")\n",
    "\n",
    "    predicted = predicted.assign_attrs(vis.vis.attrs)\n",
    "    return vis.assign({\"vis\": predicted})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789391a8",
   "metadata": {},
   "source": [
    "## Compare predicted vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11db3ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_model_vis = predict_vis(\n",
    "    vis.copy(deep=True).chunk(time=-1),\n",
    "    lsm,\n",
    "    beam_type=\"everybeam\",\n",
    "    eb_ms=eb_ms,\n",
    "    eb_coeffs=eb_coeffs,\n",
    "    station_rm=station_rm_xdr,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff341b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_model_vis_path = f\"{os.getcwd()}/expected_model_vis.vis.zarr\"\n",
    "shutil.rmtree(expected_model_vis_path, ignore_errors=True)\n",
    "\n",
    "writer = expected_model_vis.vis.to_zarr(\n",
    "    expected_model_vis_path, mode=\"w\", compute=False\n",
    ")\n",
    "dask.compute(writer, optimize_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c96a091",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_model_vis = predict_vis_new(\n",
    "    vis,\n",
    "    lsm,\n",
    "    beam_type=\"everybeam\",\n",
    "    eb_ms=eb_ms,\n",
    "    eb_coeffs=eb_coeffs,\n",
    "    gaintable=gaintable,\n",
    "    station_rm=station_rm_xdr,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ce1d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_model_vis_path = f\"{os.getcwd()}/actual_model_vis.vis.zarr\"\n",
    "shutil.rmtree(actual_model_vis_path, ignore_errors=True)\n",
    "\n",
    "writer = actual_model_vis.vis.to_zarr(actual_model_vis_path, mode=\"w\", compute=False)\n",
    "dask.compute(writer, optimize_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6b98ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_model_vis_zarr = xr.open_dataarray(\n",
    "    actual_model_vis_path, engine=\"zarr\", chunks={}\n",
    ")\n",
    "expected_model_vis_zarr = xr.open_dataarray(\n",
    "    expected_model_vis_path, engine=\"zarr\", chunks={}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9719eb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_arrays(\n",
    "    np.real(actual_model_vis_zarr.data),\n",
    "    np.real(expected_model_vis_zarr.data),\n",
    "    rtol=1e-16,\n",
    "    atol=0,\n",
    "    meta=\"Real values\",\n",
    ")\n",
    "\n",
    "compare_arrays(\n",
    "    np.imag(actual_model_vis_zarr.data),\n",
    "    np.imag(expected_model_vis_zarr.data),\n",
    "    rtol=1e-16,\n",
    "    atol=0,\n",
    "    meta=\"Imag values\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28ec21a",
   "metadata": {},
   "source": [
    "## Prediction central beams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc269258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_central_beams_new(\n",
    "    soln_time: np.ndarray,\n",
    "    frequency: np.ndarray,\n",
    "    configuration: Configuration,\n",
    "    phasecentre: SkyCoord,\n",
    "    eb_ms: str,\n",
    "    eb_coeffs: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    soln_time: np.ndarray (solution_time,)\n",
    "    frequency: np.ndarray, (frequency,)\n",
    "    configuration: Configuration\n",
    "    phasecentre: SkyCoord\n",
    "    eb_ms: str\n",
    "    eb_coeffs: str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray (solution_time, antenna, frequency, nrec1, nrec2)\n",
    "    \"\"\"\n",
    "    os.environ[\"EVERYBEAM_DATADIR\"] = eb_coeffs\n",
    "\n",
    "    beams = BeamsLow(\n",
    "        configuration=configuration,\n",
    "        direction=phasecentre,\n",
    "        frequency=frequency,\n",
    "        ms_path=eb_ms,\n",
    "        soln_time=soln_time,\n",
    "    )\n",
    "\n",
    "    # NOTE: This ID mapping will not always work when the eb_ms file is\n",
    "    # different. Should restrict the form of the eb_ms files allowed,\n",
    "    # or preferably deprecate the eb_ms option.\n",
    "    response = beams.array_response(direction=beams.beam_direction)[:, configuration.id]\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4245cb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_central_beams_ufunc(\n",
    "    soln_time: np.ndarray,\n",
    "    frequency: np.ndarray,\n",
    "    configuration: Configuration,\n",
    "    phasecentre: SkyCoord,\n",
    "    eb_ms: str,\n",
    "    eb_coeffs: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    soln_time: np.ndarray (solution_time,)\n",
    "    frequency: np.ndarray, (frequency,)\n",
    "    configuration: Configuration\n",
    "    phasecentre: SkyCoord\n",
    "    eb_ms: str\n",
    "    eb_coeffs: str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray (solution_time, frequency, antenna, nrec1, nrec2)\n",
    "    \"\"\"\n",
    "    # xarray adds a new dimension for broadcasting with frequency\n",
    "    # need to remove it\n",
    "    soln_time = soln_time.squeeze()\n",
    "\n",
    "    return generate_central_beams_new(\n",
    "        soln_time,\n",
    "        frequency,\n",
    "        configuration,\n",
    "        phasecentre,\n",
    "        eb_ms,\n",
    "        eb_coeffs,\n",
    "    ).transpose(\n",
    "        0, 2, 1, 3, 4\n",
    "    )  # time, frequency, antenna, rec1, rec2\n",
    "\n",
    "\n",
    "def prediction_central_beams_new(\n",
    "    vis: Visibility,\n",
    "    gaintable: GainTable,\n",
    "    beam_type: str = \"everybeam\",\n",
    "    eb_ms=None,\n",
    "    eb_coeffs=None,\n",
    ") -> GainTable:\n",
    "    \"\"\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Gaintable\n",
    "    \"\"\"\n",
    "    if beam_type == \"everybeam\":\n",
    "        # Do validations early on\n",
    "        if any(x is None for x in (eb_ms, eb_coeffs)):\n",
    "            raise ValueError(\n",
    "                \"eb_ms and eb_coeffs must be provided \" \"for beam_type = everybeam\"\n",
    "            )\n",
    "        # convert solution time to a chunked dask array\n",
    "        soln_time = (\n",
    "            xr.DataArray(gaintable.solution_time)\n",
    "            .rename(\"solution_time_xdr\")\n",
    "            .pipe(with_chunks, gaintable.chunksizes)\n",
    "        )\n",
    "\n",
    "        # need to calculate central beam response across entire frequency\n",
    "        frequency_xdr = (\n",
    "            xr.DataArray(vis.frequency, name=\"frequency_xdr\")\n",
    "            .pipe(with_chunks, vis.chunksizes)\n",
    "            .rename(frequency=\"solution_frequency\")\n",
    "        )\n",
    "\n",
    "        # response = generate_central_beams_new(\n",
    "        #     gaintable.solution_time,\n",
    "        #     vis.frequency.data,\n",
    "        #     vis.configuration,\n",
    "        #     vis.phasecentre,\n",
    "        #     eb_ms,\n",
    "        #     eb_coeffs,\n",
    "        # )\n",
    "\n",
    "        response: xr.DataArray = xr.apply_ufunc(\n",
    "            _generate_central_beams_ufunc,\n",
    "            soln_time,\n",
    "            frequency_xdr,\n",
    "            output_core_dims=[(\"antenna\", \"receptor1\", \"receptor2\")],\n",
    "            dask=\"parallelized\",\n",
    "            output_dtypes=[\n",
    "                np.complex128,\n",
    "            ],\n",
    "            dask_gufunc_kwargs={\n",
    "                \"output_sizes\": {\n",
    "                    \"antenna\": gaintable.antenna.size,\n",
    "                    \"receptor1\": gaintable.receptor1.size,\n",
    "                    \"receptor2\": gaintable.receptor2.size,\n",
    "                }\n",
    "            },\n",
    "            kwargs={\n",
    "                \"configuration\": vis.configuration,\n",
    "                \"phasecentre\": vis.phasecentre,\n",
    "                \"eb_ms\": eb_ms,\n",
    "                \"eb_coeffs\": eb_coeffs,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        response = response.transpose(\n",
    "            \"solution_time\", \"antenna\", \"solution_frequency\", \"receptor1\", \"receptor2\"\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        logger.info(\"No beam model to predict central beams\")\n",
    "\n",
    "        # TODO : Verify whether this has to be zeros or eye\n",
    "        response = xr.zeros_like(gaintable.gain)\n",
    "        response[..., :, :] = np.eye(2)\n",
    "\n",
    "    response = response.assign_coords(gaintable.gain.coords)\n",
    "    response = response.assign_attrs(gaintable.gain.attrs)\n",
    "\n",
    "    return gaintable.assign({\"gain\": response})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957e8304",
   "metadata": {},
   "source": [
    "## Test central beams prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a191c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_beams = prediction_central_beams(\n",
    "    vis.copy(deep=True).chunk(time=-1),\n",
    "    beam_type=beam_type,\n",
    "    eb_ms=eb_ms,\n",
    "    eb_coeffs=eb_coeffs,\n",
    ")\n",
    "\n",
    "expected_beams.load();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70be4069",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_beams = prediction_central_beams_new(\n",
    "    vis,\n",
    "    gaintable,\n",
    "    beam_type=beam_type,\n",
    "    eb_ms=eb_ms,\n",
    "    eb_coeffs=eb_coeffs,\n",
    ")\n",
    "\n",
    "actual_beams.load();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d9b723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual_beams = actual_beams.astype(np.complex64)\n",
    "# expected_beams = expected_beams.astype(np.complex64)\n",
    "\n",
    "compare_arrays(\n",
    "    np.real(actual_beams.gain.data.astype(np.complex64)),\n",
    "    np.real(expected_beams.gain.data),\n",
    "    rtol=1e-16,\n",
    "    atol=0,\n",
    "    meta=\"Real values\",\n",
    ")\n",
    "\n",
    "compare_arrays(\n",
    "    np.imag(actual_beams.gain.data.astype(np.complex64)),\n",
    "    np.imag(expected_beams.gain.data),\n",
    "    rtol=1e-16,\n",
    "    atol=0,\n",
    "    meta=\"Imag values\",\n",
    ")\n",
    "\n",
    "compare_arrays(\n",
    "    (actual_beams.gain.data.astype(np.complex64)),\n",
    "    (expected_beams.gain.data),\n",
    "    rtol=1e-16,\n",
    "    atol=0,\n",
    "    meta=\"Complex values\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5419b75",
   "metadata": {},
   "source": [
    "## Apply antenna gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6cb84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _apply_antenna_gains_to_visibility_ufunc(\n",
    "    vis: np.ndarray,\n",
    "    gains: np.ndarray,\n",
    "    antenna1: np.ndarray,\n",
    "    antenna2: np.ndarray,\n",
    "    inverse: np.ndarray = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    vis: (time, frequency, baselineid, polarisation)\n",
    "    gains: (frequency, antennas, nrec1, nrec2)\n",
    "    antenna1: (baselineid)\n",
    "        Indices of the antenna1 in all baseline pairs\n",
    "    antenna2: (baselineid)\n",
    "        Indices of the antenna2 in all baseline pairs\n",
    "    inverse: bool\n",
    "        Whether to inverse the gains before applying\n",
    "\n",
    "    Apply ufunc brings distributed dimensions to the first\n",
    "    e.g. vis becomes (time, frequency, baselineid, polarisation)\n",
    "    So need to transpose them before calling this function\n",
    "    This whole leads to double tranpose operations, which can be avoided\n",
    "    if we just write a new function to support this order?\n",
    "    Code will be duplicated, and handling of edge cases has to be done\n",
    "    carefully in both functions\n",
    "    OR force the other user of the apply_antenna_gains function to use\n",
    "    this (time, frequency, baselineid, polarisation) order.\n",
    "\n",
    "    This is an attempt at rewriting the same logic for this new order\n",
    "    \"\"\"\n",
    "    if inverse:\n",
    "        gains = np.linalg.pinv(gains)\n",
    "\n",
    "    vis_old_shape = vis.shape\n",
    "    vis_new_shape = vis.shape[:3] + (2, 2)\n",
    "\n",
    "    return np.einsum(  # pylint: disable=too-many-function-args\n",
    "        \"fbpx,tfbxy,fbqy->tfbpq\",\n",
    "        gains[:, antenna1, ...],\n",
    "        vis.reshape(vis_new_shape),\n",
    "        gains[:, antenna2, ...].conj(),\n",
    "    ).reshape(vis_old_shape)\n",
    "\n",
    "\n",
    "def apply_gaintable_to_dataset_new(\n",
    "    vis: Visibility,\n",
    "    gaintable: GainTable,\n",
    "    inverse=False,\n",
    ") -> Visibility:\n",
    "    gains = gaintable.gain\n",
    "    if gaintable.jones_type == \"B\":\n",
    "        gains = gains.rename({\"solution_frequency\": \"frequency\"})\n",
    "        # solution frequency same as vis frequency\n",
    "        # Chunking, just to be sure that they match\n",
    "        gains = gains.chunk({\"frequency\": vis.chunksizes[\"frequency\"]})\n",
    "    else:  # jones_type == T or G\n",
    "        assert gains.solution_frequency.size == 1, \"Gaintable solution frequency\"\n",
    "        \"must either match to visibility frequency, or must be of size 1\"\n",
    "        # Remove frequency dimension for appl_ufunc to work properly\n",
    "        gains = gains.isel(solution_frequency=0, drop=True)\n",
    "\n",
    "    soln_interval_slices = gaintable.soln_interval_slices\n",
    "\n",
    "    applied_vis_across_solutions = []\n",
    "    for idx, slc in enumerate(soln_interval_slices):\n",
    "        applied_vis_per_soln_interval = xr.apply_ufunc(\n",
    "            _apply_antenna_gains_to_visibility_ufunc,\n",
    "            vis.vis.isel(time=slc),\n",
    "            gains.isel(solution_time=idx, drop=True),\n",
    "            input_core_dims=[\n",
    "                [\"baselineid\", \"polarisation\"],\n",
    "                [\"antenna\", \"receptor1\", \"receptor2\"],\n",
    "            ],\n",
    "            output_core_dims=[\n",
    "                [\"baselineid\", \"polarisation\"],\n",
    "            ],\n",
    "            dask=\"parallelized\",\n",
    "            output_dtypes=[vis.vis.dtype],\n",
    "            dask_gufunc_kwargs=dict(\n",
    "                output_sizes={\n",
    "                    \"baselineid\": vis.baselineid.size,\n",
    "                    \"polarisation\": vis.polarisation.size,\n",
    "                }\n",
    "            ),\n",
    "            kwargs={\n",
    "                \"antenna1\": vis.antenna1,\n",
    "                \"antenna2\": vis.antenna2,\n",
    "                \"inverse\": inverse,\n",
    "            },\n",
    "        )\n",
    "        applied_vis_per_soln_interval = applied_vis_per_soln_interval.transpose(\n",
    "            \"time\", \"baselineid\", \"frequency\", \"polarisation\"\n",
    "        )\n",
    "        applied_vis_across_solutions.append(applied_vis_per_soln_interval)\n",
    "\n",
    "    applied: xr.DataArray = xr.concat(applied_vis_across_solutions, dim=\"time\")\n",
    "\n",
    "    applied = applied.assign_attrs(vis.vis.attrs)\n",
    "    return vis.assign({\"vis\": applied})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148536aa",
   "metadata": {},
   "source": [
    "## Test apply central beams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50a15cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "beams_to_apply = expected_beams.copy(deep=True)\n",
    "# Applying actual beams itself to test this function in isolation\n",
    "beams_to_apply.gain.data = actual_beams.gain.data\n",
    "beams_to_apply = beams_to_apply.chunk(frequency=vis.chunksizes[\"frequency\"])\n",
    "\n",
    "expected_beam_corr_vis = apply_gaintable_to_dataset(\n",
    "    vis.copy(deep=True).chunk(time=-1), beams_to_apply, inverse=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89ec530",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_beam_corr_vis_path = f\"{os.getcwd()}/expected_beam_corr_vis.vis.zarr\"\n",
    "shutil.rmtree(expected_beam_corr_vis_path, ignore_errors=True)\n",
    "\n",
    "writer = expected_beam_corr_vis.vis.to_zarr(\n",
    "    expected_beam_corr_vis_path, mode=\"w\", compute=False\n",
    ")\n",
    "dask.compute(writer, optimize_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996895b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_beam_corr_vis = apply_gaintable_to_dataset_new(vis, actual_beams, inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3b6ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_beam_corr_vis_path = f\"{os.getcwd()}/actual_beam_corr_vis.vis.zarr\"\n",
    "shutil.rmtree(actual_beam_corr_vis_path, ignore_errors=True)\n",
    "\n",
    "writer = actual_beam_corr_vis.vis.to_zarr(\n",
    "    actual_beam_corr_vis_path, mode=\"w\", compute=False\n",
    ")\n",
    "dask.compute(writer, optimize_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8f1943",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_beam_corr_vis_zarr = xr.open_dataarray(\n",
    "    actual_beam_corr_vis_path, engine=\"zarr\", chunks={}\n",
    ")\n",
    "expected_beam_corr_vis_zarr = xr.open_dataarray(\n",
    "    expected_beam_corr_vis_path, engine=\"zarr\", chunks={}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b13444",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_arrays(\n",
    "    np.real(actual_beam_corr_vis_zarr.data),\n",
    "    np.real(expected_beam_corr_vis_zarr.data),\n",
    "    rtol=1e-32,\n",
    "    atol=0,\n",
    "    meta=\"Real values\",\n",
    ")\n",
    "\n",
    "compare_arrays(\n",
    "    np.imag(actual_beam_corr_vis_zarr.data),\n",
    "    np.imag(expected_beam_corr_vis_zarr.data),\n",
    "    rtol=1e-32,\n",
    "    atol=0,\n",
    "    meta=\"Imag values\",\n",
    ")\n",
    "\n",
    "compare_arrays(\n",
    "    (actual_beam_corr_vis_zarr.data),\n",
    "    (expected_beam_corr_vis_zarr.data),\n",
    "    rtol=1e-32,\n",
    "    atol=0,\n",
    "    meta=\"Complex values\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bc1bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ska-sdp-instrumental-calibration-vujiG8jS-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
